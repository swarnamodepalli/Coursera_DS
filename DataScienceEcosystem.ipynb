{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Data Science Tools and Ecosystem",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Introduction to Data Science Tools and Ecosystem\n\nWelcome to this notebook on Data Science Tools and Ecosystem! In the world of data science, having access to the right tools is essential for efficiently analyzing and interpreting data. This notebook aims to provide an overview of some of the key data science tools and the ecosystem that empowers data scientists to work effectively with data.\n\nData science involves a multidisciplinary approach, combining expertise in programming, statistics, and domain knowledge to extract valuable insights from data. Throughout this notebook, we will explore various data science languages, libraries, and frameworks that are commonly used in the data science workflow.\n\nWe will start by discussing popular data science languages such as Python, R, and SQL. These languages serve as the foundation for data manipulation, analysis, and visualization. Additionally, we will explore the rich ecosystem of data science libraries available in Python, including Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, and TensorFlow, each playing a specific role in the data analysis process.\n\nMoreover, we will touch upon other data science tools like Jupyter Notebook, which provides an interactive and collaborative environment for data exploration and documentation. Understanding the role of these tools and how they complement each other is crucial for data scientists to efficiently solve real-world problems and make data-driven decisions.\n\nSo let's embark on this journey to discover the powerful data science tools and gain insights into the ecosystem that drives innovation and discovery in the field of data science. Let's get started!\n",
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Introduction to Data Science Tools and Ecosystem\n\nWelcome to this notebook on Data Science Tools and Ecosystem! In the world of data science, having access to the right tools is essential for efficiently analyzing and interpreting data. This notebook aims to provide an overview of some of the key data science tools and the ecosystem that empowers data scientists to work effectively with data.\n\nSome of the popular languages that Data Scientists use are:\n\n1. **Python**: Python is one of the most widely used and versatile programming languages in data science. It offers a rich ecosystem of libraries and frameworks, such as Pandas, NumPy, SciPy, Scikit-learn, and TensorFlow, making it a favorite among data scientists for data manipulation, visualization, and machine learning.\n\n2. **R**: R is another powerful language specifically designed for statistical computing and data analysis. It has a vast collection of packages, including ggplot2, dplyr, and caret, that provide excellent tools for data visualization, data manipulation, and statistical modeling.\n\n3. **SQL**: SQL (Structured Query Language) is essential for working with relational databases, making it a crucial tool for data retrieval and manipulation in data science.\n\n4. **Julia**: Julia is a high-level, high-performance programming language for technical computing. It has gained popularity in the data science community due to its speed and ease of use for numerical and scientific computing tasks.\n\nThroughout this notebook, we will explore these languages and other data science libraries and tools that are commonly used in the data science workflow. Understanding and mastering these tools will empower you to become a proficient data scientist capable of extracting valuable insights from data and making data-driven decisions.\n\nSo let's embark on this journey to discover the powerful data science tools and gain insights into the ecosystem that drives innovation and discovery in the field of data science. Let's get started!\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Introduction to Data Science Tools and Ecosystem\n\nSome of the commonly used libraries used by Data Scientists include:\n\n1. **Pandas**: Pandas is a powerful library for data manipulation and analysis. It provides data structures like DataFrames and Series, making it easy to clean, transform, and analyze tabular data.\n\n2. **NumPy**: NumPy is the fundamental package for numerical computing in Python. It provides support for large, multi-dimensional arrays and matrices, along with a wide range of mathematical functions to operate on these arrays efficiently.\n\n3. **Matplotlib**: Matplotlib is a widely used library for creating static, interactive, and animated visualizations in Python. It offers a flexible interface for producing various types of plots and charts.\n\n4. **Seaborn**: Seaborn is a higher-level data visualization library built on top of Matplotlib. It provides an easy-to-use interface to create attractive and informative statistical graphics.\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "\n\n ## A single column table listing three development environment open-source tools used in data science:\n\n| Data Science Tools      |\n|-------------------------|\n| Jupyter Notebook        |\n| Visual Studio Code (VS Code) |\n| PyCharm                 |\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Below are a few examples of evaluating arithmetic expressions in Python.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#this is a simple arithmetic expression to multiply then add integer\n3+7*8",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "59"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# This will convert 200 minutes to hours by dividing by 60.\nminutes = 200\nhours = minutes / 60\nprint(hours)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "text": "3.3333333333333335\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives:\n\nBelow are some of the key takeaways and objectives that this notebook covered:\n\n- **List popular languages for Data Science**: We explored some of the most commonly used programming languages in data science, including Python, R, and SQL.\n\n- **Introduce essential data science libraries**: We discussed important data science libraries like Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, and TensorFlow, along with their functionalities.\n\n- **Explore Data Science Tools and Ecosystem**: We introduced various data science tools and the ecosystem that empowers data scientists to efficiently analyze and interpret data.\n\n- **Understand the data science process**: We touched upon the data science process, including data acquisition, data cleaning, exploratory data analysis (EDA), feature engineering, model selection, and evaluation.\n\n- **Evaluate arithmetic expressions**: We showcased examples of evaluating arithmetic expressions in Python, demonstrating basic mathematical operations.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Author\n\nMy name is [Nikhila Prasanthi].",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}